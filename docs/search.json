[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "lab6",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\nWarning: package 'purrr' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.3\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.7     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.2.1     \n\n\nWarning: package 'dials' was built under R version 4.4.3\n\n\nWarning: package 'parsnip' was built under R version 4.4.3\n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\nWarning: package 'tune' was built under R version 4.4.3\n\n\nWarning: package 'workflows' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(patchwork)\n\n\nroot &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf',\n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files &lt;- glue('{root}/camels_{types}.txt')\nlocal_files &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) %&gt;%\n  power_full_join(by = 'gauge_id')\n\nQ1: zero_q_freq represents how often the streams’ flow is recorded at zero.\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.4.3\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\nQ2:\n\n# Map 1: Aridity\nmap_aridity &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity), size = 2) +\n  scale_color_viridis_c(option = \"C\", name = \"Aridity\") +\n  ggthemes::theme_map() +\n  labs(title = \"Sites Colored by Aridity\")\n\n# Map 2: Mean Precipitation (p_mean)\nmap_pmean &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean), size = 2) +\n  scale_color_viridis_c(option = \"D\", name = \"Mean Precipitation (mm)\") +\n  ggthemes::theme_map() +\n  labs(title = \"Sites Colored by Mean Precipitation\")\n\n# Combine with patchwork\nmap_aridity + map_pmean\n\n\n\n\n\n\n\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n#splitting data\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n\n\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Sanity Interaction term from recipe ... these should be equal!!\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\n\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n\n  add_recipe(rec) %&gt;%\n \n  add_model(rf_model) %&gt;%\n \n  fit(data = camels_train) \n\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nWarning: package 'ranger' was built under R version 4.4.3\n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.562  0.0252    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.772  0.0259    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\nQ3:\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(baguette)\n\nxgb_model &lt;- boost_tree(\n  trees = 500,\n  learn_rate = 0.05\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nnn_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nall_models &lt;- workflow_set(\n  preproc = list(rec),\n  models = list(\n    linear_regression = lm_model,\n    random_forest     = rf_model,\n    xgboost           = xgb_model,\n    neural_net        = nn_model\n  )\n)\n\nall_model_res &lt;- workflow_map(\n  all_models,\n  fn = \"fit_resamples\",\n  resamples = camels_cv,\n  metrics = metric_set(rsq, rmse),\n  control = control_resamples(\n    save_pred = TRUE,\n    verbose = TRUE\n  )\n)\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\nautoplot(all_model_res)\n\n\n\n\n\n\n\nrank_results(all_model_res, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_random_fo… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_random_fo… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_neural_net Prepro… rmse    0.582  0.0345    10 recipe       bag_…     2\n4 recipe_neural_net Prepro… rsq     0.770  0.0246    10 recipe       bag_…     2\n5 recipe_linear_re… Prepro… rmse    0.569  0.0260    10 recipe       line…     3\n6 recipe_linear_re… Prepro… rsq     0.770  0.0223    10 recipe       line…     3\n7 recipe_xgboost    Prepro… rmse    0.632  0.0261    10 recipe       boos…     4\n8 recipe_xgboost    Prepro… rsq     0.721  0.0295    10 recipe       boos…     4\n\nrank_results(all_model_res, rank_metric = \"rmse\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_random_fo… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_random_fo… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_linear_re… Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_re… Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n5 recipe_neural_net Prepro… rmse    0.582  0.0345    10 recipe       bag_…     3\n6 recipe_neural_net Prepro… rsq     0.770  0.0246    10 recipe       bag_…     3\n7 recipe_xgboost    Prepro… rmse    0.632  0.0261    10 recipe       boos…     4\n8 recipe_xgboost    Prepro… rsq     0.721  0.0295    10 recipe       boos…     4\n\n\nAccording to the results, it seems like the random forest model is the most effective, and the one I would move forward with.\n\n# 1. Set seed for reproducibility\nset.seed(123)\n\n# 2. Initial data split: 75% training, 25% testing\ncamels_split &lt;- initial_split(camels, prop = 0.75)\n\n# 3. Extract training and testing sets\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\n# 4. Create 10-fold cross-validation from training data\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# This recipe models log mean streamflow using both climate and physical landscape features\nrec &lt;- recipe(logQmean ~ aridity + p_mean + pet_mean + slope_mean + frac_forest, data = camels_train) %&gt;%\n  step_log(aridity, p_mean, pet_mean) %&gt;%  # Apply log-transform to skewed variables\n  step_normalize(all_predictors()) %&gt;%     # Normalize predictors for comparability\n  step_naomit(all_predictors(), all_outcomes()) # Remove rows with missing data\n\ndefining 3 models\n\nnn_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nxgb_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nnn_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nSetting workflows\nEvaluation:\n\n# Create a named list of models\nmodels &lt;- list(\n  rf = rf_model,\n  xgb = xgb_model,\n  nn = nn_model\n)\n\n# Build the workflow set\nwf_set &lt;- workflow_set(\n  preproc = list(full_recipe = rec),\n  models = models\n)\n\n# Fit the models to the resamples\nwf_res &lt;- wf_set %&gt;%\n  workflow_map(\n    fn = \"fit_resamples\",\n    resamples = camels_cv,\n    control = control_resamples(save_pred = TRUE, verbose = TRUE)\n  )\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold01: preprocessor 1/1\n\n\n✓ Fold01: preprocessor 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1\n\n\n✓ Fold01: preprocessor 1/1, model 1/1\n\n\ni Fold01: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold01: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold02: preprocessor 1/1\n\n\n✓ Fold02: preprocessor 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1\n\n\n✓ Fold02: preprocessor 1/1, model 1/1\n\n\ni Fold02: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold02: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold03: preprocessor 1/1\n\n\n✓ Fold03: preprocessor 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1\n\n\n✓ Fold03: preprocessor 1/1, model 1/1\n\n\ni Fold03: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold03: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold04: preprocessor 1/1\n\n\n✓ Fold04: preprocessor 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1\n\n\n✓ Fold04: preprocessor 1/1, model 1/1\n\n\ni Fold04: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold04: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold05: preprocessor 1/1\n\n\n✓ Fold05: preprocessor 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1\n\n\n✓ Fold05: preprocessor 1/1, model 1/1\n\n\ni Fold05: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold05: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold06: preprocessor 1/1\n\n\n✓ Fold06: preprocessor 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1\n\n\n✓ Fold06: preprocessor 1/1, model 1/1\n\n\ni Fold06: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold06: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold07: preprocessor 1/1\n\n\n✓ Fold07: preprocessor 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1\n\n\n✓ Fold07: preprocessor 1/1, model 1/1\n\n\ni Fold07: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold07: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold08: preprocessor 1/1\n\n\n✓ Fold08: preprocessor 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1\n\n\n✓ Fold08: preprocessor 1/1, model 1/1\n\n\ni Fold08: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold08: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold09: preprocessor 1/1\n\n\n✓ Fold09: preprocessor 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1\n\n\n✓ Fold09: preprocessor 1/1, model 1/1\n\n\ni Fold09: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold09: preprocessor 1/1, model 1/1 (predictions)\n\n\ni Fold10: preprocessor 1/1\n\n\n✓ Fold10: preprocessor 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1\n\n\n✓ Fold10: preprocessor 1/1, model 1/1\n\n\ni Fold10: preprocessor 1/1, model 1/1 (extracts)\n\n\ni Fold10: preprocessor 1/1, model 1/1 (predictions)\n\n# Visualize model performance\nautoplot(wf_res)\n\n\n\n\n\n\n\n# Rank by R-squared (higher is better)\nrank_results(wf_res, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 6 × 9\n  wflow_id        .config   .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 full_recipe_nn  Preproce… rmse    0.339 0.0289     10 recipe       bag_…     1\n2 full_recipe_nn  Preproce… rsq     0.916 0.0143     10 recipe       bag_…     1\n3 full_recipe_rf  Preproce… rmse    0.372 0.0183     10 recipe       rand…     2\n4 full_recipe_rf  Preproce… rsq     0.906 0.00849    10 recipe       rand…     2\n5 full_recipe_xgb Preproce… rmse    0.396 0.0219     10 recipe       boos…     3\n6 full_recipe_xgb Preproce… rsq     0.891 0.0113     10 recipe       boos…     3\n\n\nAccording to these results, bag_mlp is likely the best model in this scenario.\n\nfinal_wf &lt;- workflow() %&gt;%\n  add_model(rf_model) %&gt;%\n  add_recipe(rec)\n\n\nfinal_fit &lt;- final_wf %&gt;%\n  fit(data = camels_train)\n\n\nfinal_results &lt;- augment(final_fit, new_data = camels_test)\n\n\n\nggplot(final_results, aes(x = logQmean, y = .pred, color = aridity)) +\n  geom_point(alpha = 0.7) +\n  geom_abline(linetype = \"dashed\", color = \"gray30\") +\n  scale_color_viridis_c(option = \"C\") +\n  theme_minimal() +\n  labs(\n    title = \"Observed vs Predicted Streamflow (Log Scale)\",\n    x = \"Observed Log Mean Flow\",\n    y = \"Predicted Log Mean Flow\",\n    color = \"Aridity Index\"\n  )"
  }
]